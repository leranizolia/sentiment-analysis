{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiments_analysis_full.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e46b4d32f48490382413dffb56ac86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad1bbedd25cb4e049efa96fa1e16e76f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_951182d60c4a4cc8ba54ddd8d9670f16",
              "IPY_MODEL_960f94620b2e4aa4a0630a3b3eb97e9f"
            ]
          }
        },
        "ad1bbedd25cb4e049efa96fa1e16e76f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "951182d60c4a4cc8ba54ddd8d9670f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d55b9c47de9463c90c8d0c1948692f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc04a39ea1264c33ab247bc228618ee5"
          }
        },
        "960f94620b2e4aa4a0630a3b3eb97e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb9fbf244a0d451c83462b980aa4b498",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "1917495it [02:04, 15442.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74f993c739834e0d942292b54a2ded78"
          }
        },
        "7d55b9c47de9463c90c8d0c1948692f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc04a39ea1264c33ab247bc228618ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb9fbf244a0d451c83462b980aa4b498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74f993c739834e0d942292b54a2ded78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLzeLjeugxxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "c5f3572e-5369-4528-8ef3-f9033b2c6b9c"
      },
      "source": [
        "#ячейка, которая даёт доступ к датасетам соревнований на kaggle (при необходимости надо ещё сделать !pip install kaggle)\n",
        "import os\n",
        "os.environ[\"KAGGLE_USERNAME\"]=\"valeriianizolia\"\n",
        "os.environ['KAGGLE_KEY']='cac25c733910006ce9e1cef86202110f'\n",
        "!kaggle competitions download -c iad-deep-learning-sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading y_train.csv.zip to /content\n",
            "  0% 0.00/8.37M [00:00<?, ?B/s]\n",
            "100% 8.37M/8.37M [00:00<00:00, 77.3MB/s]\n",
            "Downloading x_train.txt.zip to /content\n",
            " 97% 577M/595M [00:05<00:00, 69.9MB/s]\n",
            "100% 595M/595M [00:05<00:00, 109MB/s] \n",
            "Downloading random_prediction.csv.zip to /content\n",
            "  0% 0.00/2.08M [00:00<?, ?B/s]\n",
            "100% 2.08M/2.08M [00:00<00:00, 141MB/s]\n",
            "Downloading x_test.txt.zip to /content\n",
            " 96% 65.0M/68.0M [00:00<00:00, 25.0MB/s]\n",
            "100% 68.0M/68.0M [00:00<00:00, 82.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw4Ikci09Anp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "27249da8-3808-4a28-a634-075ae17e7b81"
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  y_train.csv.zip\n",
            "  inflating: y_train.csv             \n",
            "\n",
            "Archive:  x_test.txt.zip\n",
            "  inflating: x_test.txt              \n",
            "\n",
            "Archive:  random_prediction.csv.zip\n",
            "  inflating: random_prediction.csv   \n",
            "\n",
            "Archive:  x_train.txt.zip\n",
            "  inflating: x_train.txt             \n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9bHnBxF9Wws"
      },
      "source": [
        "#для очистки памяти\n",
        "os.remove(\"x_test.txt.zip\")\n",
        "os.remove(\"x_train.txt.zip\")\n",
        "os.remove(\"y_train.csv.zip\")\n",
        "os.remove(\"random_prediction.csv.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3KhdKfgjLua"
      },
      "source": [
        "import pandas as pd\n",
        "random_prediction = pd.read_csv(\"random_prediction.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "x_train = pd.read_fwf('x_train.txt', header=None)\n",
        "x_train.to_csv(\"x_train.csv\")\n",
        "x_test = pd.read_fwf('x_test.txt', header=None)\n",
        "x_test.to_csv(\"x_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAbLWYNc-YjA"
      },
      "source": [
        "os.remove(\"x_train.txt\")\n",
        "os.remove(\"x_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayLNYIUc-4MA"
      },
      "source": [
        "def delete_punctuation(x):\n",
        "    punctuation = list(string.punctuation)\n",
        "    return ''.join([a if a not in punctuation + ['\\n'] else ' ' for a in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAViryiE-M2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "8080067e-7294-4f8f-c4d0-edfd7749edf9"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          Stuning even for the non-gamer: This sound tra...\n",
              "1          The best soundtrack ever to anything.: I'm rea...\n",
              "2          Amazing!: This soundtrack is my favorite music...\n",
              "3          Excellent Soundtrack: I truly like this soundt...\n",
              "4          Remember, Pull Your Jaw Off The Floor After He...\n",
              "                                 ...                        \n",
              "3599995    Don't do it!!: The high chair looks great when...\n",
              "3599996    Looks nice, low functionality: I have used thi...\n",
              "3599997    compact, but hard to clean: We have a small ho...\n",
              "3599998    what is it saying?: not sure what this book is...\n",
              "3599999    Makes My Blood Run Red-White-And-Blue: I agree...\n",
              "Name: 0, Length: 3600000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJQqc6m1Qni"
      },
      "source": [
        "import string\n",
        "# приведение всех слов к нижнему регистру\n",
        "x_train[0] = x_train[0].apply(lambda x: x.lower())\n",
        "x_test[0] = x_test[0].apply(lambda x: x.lower())\n",
        "# удаление пунктуации\n",
        "x_train[0] = x_train[0].apply(delete_punctuation)\n",
        "x_test[0] = x_test[0].apply(delete_punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEuObC0P2M3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "0f41cdfb-223e-4ae7-f1cd-a7b1b312ddce"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-22 19:15:50--  http://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip [following]\n",
            "--2019-12-22 19:15:51--  https://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.42B.300d.zip [following]\n",
            "--2019-12-22 19:15:51--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877802108 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  2.07MB/s    in 14m 34s \n",
            "\n",
            "2019-12-22 19:30:26 (2.05 MB/s) - ‘glove.42B.300d.zip’ saved [1877802108/1877802108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YIHY0J22PiV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "39909353-9113-422f-a139-b2fe9ace11b1"
      },
      "source": [
        "from keras.layers import Dense, Input, GRU, Embedding, Dropout, Bidirectional\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqqj9wGB2UkV"
      },
      "source": [
        "import os, zipfile\n",
        "file_name = os.path.abspath('./glove.42B.300d.zip') # get full path of files\n",
        "zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
        "zip_ref.extractall('./') # extract file to dir\n",
        "zip_ref.close() # close file\n",
        "os.remove(file_name) # delete zipped file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4X8tR4m2bE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "4e46b4d32f48490382413dffb56ac86c",
            "ad1bbedd25cb4e049efa96fa1e16e76f",
            "951182d60c4a4cc8ba54ddd8d9670f16",
            "960f94620b2e4aa4a0630a3b3eb97e9f",
            "7d55b9c47de9463c90c8d0c1948692f7",
            "fc04a39ea1264c33ab247bc228618ee5",
            "eb9fbf244a0d451c83462b980aa4b498",
            "74f993c739834e0d942292b54a2ded78"
          ]
        },
        "outputId": "7915fdaa-6f06-4d7b-9770-fb7aea499631"
      },
      "source": [
        "import numpy as np\n",
        "f = open('./glove.42B.300d.txt')\n",
        "\n",
        "embeddings_index = dict() \n",
        "for line in tqdm_notebook(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e46b4d32f48490382413dffb56ac86c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi5sap3-KDu1"
      },
      "source": [
        "os.remove(\"glove.42B.300d.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcqWnVTtKXIc"
      },
      "source": [
        "os.remove(\"random_prediction.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXBWbQ7p2gXf"
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 100000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 150 # max number of words in a comment to use (приблизительная максимальная длина отзывов теперь 20 слов)\n",
        "\n",
        "list_sentences_train = x_train[0].values\n",
        "y = y_train[\"Probability\"].values\n",
        "list_sentences_test = x_test[0].values\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
        "x_train_pad = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "x_test_pad = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkdzGbfjM88M"
      },
      "source": [
        "os.remove(\"x_train.csv\")\n",
        "os.remove(\"y_train.csv\")\n",
        "os.remove(\"x_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1LblgrE40tk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ca6296ac-d480-472a-8a7b-e18662cd8503"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
        "emb_mean, emb_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.005720101, 0.2951066)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaxGLCEZ5BOb"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "unknown_words = set()\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "    else: unknown_words.add(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjQ2SWu8OoV3"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "  auc=tf.metrics.auc(y_true, y_pred)[1]\n",
        "  K.get_session().run(tf.local_variables_initializer())\n",
        "  return auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9K24OtJYjId"
      },
      "source": [
        "del x_train, x_test, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K76XLuCP5Msc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "4d692ec7-87fc-4e30-bf18-8bc1cc98c649"
      },
      "source": [
        "import tensorflow as tf\n",
        "input_layer = Input((maxlen,), name = 'reviews')\n",
        "embedding_layer = Embedding(max_features, embed_size, input_length=maxlen, \n",
        "                            weights=[embedding_matrix], \n",
        "                            trainable = False)(input_layer)\n",
        "x = Bidirectional(GRU(128, return_sequences=True))(embedding_layer)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Bidirectional(GRU(128, return_sequences=False))(x)\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "output_layer = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(clipvalue=1, clipnorm=1),\n",
        "                  metrics=[auc])\n",
        "print(model.summary())\n",
        "\n",
        "def schedule(ind):\n",
        "    a = [0.001, 0.001, 0.0001]\n",
        "    return a[ind]\n",
        "\n",
        "lr = LearningRateScheduler(schedule)\n",
        "    \n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=4,\n",
        "                           verbose=1,\n",
        "                           min_delta=1e-4)\n",
        "\n",
        "\n",
        "history = model.fit(x_train_pad, y, batch_size=256, epochs = 3, \n",
        "                    validation_split = 0.1, verbose = 1, callbacks = [lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reviews (InputLayer)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 150, 300)          30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 150, 256)          329472    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 150, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 256)               295680    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 30,641,665\n",
            "Trainable params: 641,665\n",
            "Non-trainable params: 30,000,000\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 3240000 samples, validate on 360000 samples\n",
            "Epoch 1/3\n",
            "3240000/3240000 [==============================] - 7815s 2ms/step - loss: 0.1498 - auc: 0.9758 - val_loss: 0.1257 - val_auc: 0.9858\n",
            "Epoch 2/3\n",
            "3240000/3240000 [==============================] - 7727s 2ms/step - loss: 0.1198 - auc: 0.9872 - val_loss: 0.1206 - val_auc: 0.9881\n",
            "Epoch 3/3\n",
            " 141568/3240000 [>.............................] - ETA: 1:56:41 - loss: 0.1078 - auc: 0.9882"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b4fbf7ea54b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m history = model.fit(x_train_pad, y, batch_size=256, epochs = 3, \n\u001b[0;32m---> 31\u001b[0;31m                     validation_split = 0.1, verbose = 1, callbacks = [lr])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8R0v6BWud8_"
      },
      "source": [
        "ind = np.arange(1, x_test_pad.shape[0]+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buaNcywFsJcl"
      },
      "source": [
        "predicted_probs = model.predict(x_test_pad,batch_size = 1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG5ix_WQEPda"
      },
      "source": [
        "a = np.arange(1, x_test_pad.shape[0]+1)\n",
        "predictions = pd.DataFrame(a, columns = ['Id'])\n",
        "predictions[\"Probability\"]= predicted_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az4lmhJs4Z0I"
      },
      "source": [
        "predictions.to_csv(\"submission_full.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}